#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# AEGIS SHIELD: ADVANCED SYSTEM DEFENSE PROTOCOL Â© 2025

import os
import platform
import subprocess
import psutil
import logging
import re
import socket
import threading
import time
import random
import hashlib
import ssl
import json
from datetime import datetime
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress
from getpass import getuser
from cryptography.fernet import Fernet
from concurrent.futures import ThreadPoolExecutor
import logging.handlers

# Setup rich console with enhanced styling
console = Console(highlight=False)

# Configure secure logging with rotation
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s')
log_handler = logging.handlers.RotatingFileHandler('aegis_defense.log', maxBytes=10485760, backupCount=5)
log_handler.setFormatter(log_formatter)

logger = logging.getLogger("AEGIS")
logger.setLevel(logging.INFO)
logger.addHandler(log_handler)

# Generate encryption key for secure communications
def generate_encryption_key():
    return Fernet.generate_key()

ENCRYPTION_KEY = generate_encryption_key()
cipher_suite = Fernet(ENCRYPTION_KEY)

# ========================
# THREAT INTELLIGENCE ENGINE
# ========================
class ThreatIntelligence:
    def __init__(self):
        self.threat_data = {
            "ips": set(),
            "domains": set(),
            "file_hashes": set(),
            "attack_patterns": set(),
            "last_updated": datetime.now()
        }
        self.load_threat_intel()
        
    def load_threat_intel(self):
        """Load threat intelligence from local database or remote API"""
        # Simulated threat data (would be replaced with actual API call)
        self.threat_data["ips"].update([
            "192.168.1.100", "10.0.0.1", "172.16.0.1", 
            "45.33.32.156", "185.130.44.108", "91.234.99.38"
        ])
        self.threat_data["domains"].update([
            "malicious-site.com", "evil-domain.net", "badactor.org", 
            "phishing-attempt.co", "ransomware-c2.io"
        ])
        self.threat_data["file_hashes"].update([
            "e1a73c9e81a721780d3fa52f2b84c14a", "5d41402abc4b2a76b9719d911017c592",
            "aaf4c61ddcc5e8a2dabede0f3b482cd9", "7d793037a0760186574b0282f2f435e7"
        ])
        self.threat_data["attack_patterns"].update([
            r"(?i)(SELECT.*FROM.*WHERE)", r"(?i)(UNION.*SELECT)",  # SQL injection
            r"<script.*>.*</script>", r"(?i)(document\.cookie)",    # XSS
            r"(?i)(eval\(.*\))", r"(?i)(exec\(.*\))"               # Command injection
        ])
        logger.info(f"Loaded threat intelligence with {len(self.threat_data['ips'])} IPs, " 
                   f"{len(self.threat_data['domains'])} domains, "
                   f"{len(self.threat_data['file_hashes'])} file hashes")
    
    def is_ip_malicious(self, ip):
        return ip in self.threat_data["ips"]
    
    def is_domain_malicious(self, domain):
        return any(domain.endswith(d) for d in self.threat_data["domains"])
    
    def is_hash_malicious(self, file_hash):
        return file_hash in self.threat_data["file_hashes"]
    
    def detect_attack_pattern(self, data):
        for pattern in self.threat_data["attack_patterns"]:
            if re.search(pattern, data):
                return True
        return False

# ========================
# ADVANCED BANNER SENDER
# ========================
def send_deception_banner(port, target_ip='localhost', aggressive=False):
    """
    Sends a deceptive banner that appears vulnerable but actually
    gathers intelligence about the attacker.
    """
    deception_banners = [
        # Fake vulnerable SSH banner
        "SSH-2.0-OpenSSH_5.3p1 Debian-3ubuntu4\r\n",
        # Fake vulnerable FTP banner
        "220 FTP Server Ready. Version 1.3.28\r\n",
        # Fake vulnerable SMTP banner
        "220 ESMTP Postfix 2.0.16 Ready\r\n",
        # Fake vulnerable Telnet banner
        "\r\nWelcome to Legacy Telnet Server v2.3\r\nLogin: ",
        # Fake vulnerable database banner
        "MySQL Server 4.1.7, connection accepted.\r\n",
    ]
    
    # Honeypot ASCII art to confuse attackers
    honeypot_banner = r"""
       _    _____ ____ ___ ____    ____  _   _ ___ _____ _     ____  
      / \  | ____/ ___|_ _/ ___|  / ___|| | | |_ _| ____| |   |  _ \ 
     / _ \ |  _|| |  _ | |\___ \  \___ \| |_| || ||  _| | |   | | | |
    / ___ \| |__| |_| || | ___) |  ___) |  _  || || |___| |___| |_| |
   /_/   \_\_____\____|___|____/  |____/|_| |_|___|_____|_____|____/ 
                                                                     
   [!] INTRUSION DETECTED - CONNECTION TRACKED - COUNTERATTACK INITIATED
    """
    
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(2.0)
            s.connect((target_ip, port))
            
            # Send a deceptive banner first
            banner = random.choice(deception_banners)
            s.sendall(banner.encode('utf-8'))
            
            # If aggressive mode, follow with honeypot banner and data collection
            if aggressive:
                # Wait briefly to simulate a vulnerable service
                time.sleep(0.5)
                
                # Send honeypot banner
                s.sendall(honeypot_banner.encode('utf-8'))
                
                # Attempt to collect data from the connection
                try:
                    s.settimeout(1.0)
                    attacker_data = s.recv(1024)
                    if attacker_data:
                        # Log any credentials or commands attempted
                        logger.warning(f"Collected attacker data on port {port}: {attacker_data.decode('utf-8', errors='ignore')}")
                except Exception:
                    pass
                
                # Send confusion data for 5 cycles
                for _ in range(5):
                    # Random garbage data that looks like sensitive information
                    fake_data = f"SYS_TOKEN={hashlib.md5(os.urandom(10)).hexdigest()}\r\n"
                    fake_data += f"SESSION_ID={hashlib.sha256(os.urandom(10)).hexdigest()}\r\n"
                    fake_data += "CONNECTION_RESET=1\r\n"
                    
                    s.sendall(fake_data.encode('utf-8'))
                    time.sleep(0.2)
            
            return True
    except Exception as e:
        logger.error(f"Failed to send deception banner to {target_ip}:{port}: {str(e)}")
        return False

# ========================
# ENHANCED ETHICAL SAFEGUARDS
# ========================
def safety_check():
    console.print(Panel.fit(
        "[bold red]AEGIS SHIELD: ADVANCED DEFENSE PROTOCOL[/]\n"
        "[yellow]This tool makes real system changes and monitors network activity![/]", 
        style="red", border_style="red"
    ))
    
    # Multi-factor verification to prevent accidental execution
    verification_code = hashlib.md5(str(datetime.now().timestamp()).encode()).hexdigest()[:6].upper()
    console.print(f"[bold]Verification code: {verification_code}[/]")
    
    if input("Type 'I ACCEPT FULL RESPONSIBILITY' followed by the verification code: ").strip() != f"I ACCEPT FULL RESPONSIBILITY {verification_code}":
        console.print("[red]Operation cancelled - Validation failed[/]")
        exit()
    
    # Check for appropriate privileges
    if platform.system().lower() != "windows" and os.geteuid() != 0:
        console.print("[red]This tool requires root/administrator privileges[/]")
        exit()

# ========================
# QUANTUM GUARD FILE SCANNER
# ========================
class QuantumFileScanner:
    """
    Advanced file scanner that uses multiple detection methods including:
    - Traditional signatures
    - Behavioral analysis
    - ML-based anomaly detection
    - Memory scanning for fileless malware
    """
    def __init__(self, threat_intel):
        self.scan_results = []
        self.system_type = platform.system().lower()
        self.threat_intel = threat_intel
        self.av_config = self._get_av_config()
        
    def _get_av_config(self):
        av_config = {
            'windows': {
                'name': 'Defender',
                'scan_cmd': ['powershell.exe', 'Start-MpScan', '-ScanType'],
                'query_cmd': ['powershell.exe', 'Get-MpThreat']
            },
            'linux': {
                'name': 'ClamAV',
                'scan_cmd': ['clamscan', '-r', '--infected'],
                'query_cmd': ['clamscan', '-r', '--infected']
            },
            'darwin': {
                'name': 'ClamAV',
                'scan_cmd': ['clamscan', '-r', '--infected'],
                'query_cmd': ['clamscan', '-r', '--infected']
            }
        }
        return av_config.get(self.system_type)

    def scan(self, quick=False, memory_scan=True):
        if not self.av_config:
            logger.error("Unsupported platform for antivirus scanning")
            return []
            
        with Progress() as progress:
            scan_task = progress.add_task("[cyan]Scanning filesystem...", total=100)
            
            # First perform standard antivirus scan
            self.scan_results = self._perform_av_scan(quick)
            progress.update(scan_task, advance=50)
            
            # Then perform custom scans for high-risk areas
            self.scan_results.extend(self._custom_high_risk_scan())
            progress.update(scan_task, advance=25)
            
            # Finally do memory scanning if requested
            if memory_scan:
                self.scan_results.extend(self._memory_scan())
            progress.update(scan_task, advance=25)
            
        logger.info(f"Scan complete. Found {len(self.scan_results)} threats")
        return self.scan_results

    def _perform_av_scan(self, quick):
        try:
            if self.system_type == 'windows':
                scan_type = "QuickScan" if quick else "FullScan"
                subprocess.run(self.av_config['scan_cmd'] + [scan_type],
                               check=True, stdout=subprocess.DEVNULL)
                result = subprocess.run(self.av_config['query_cmd'], 
                                       capture_output=True, text=True)
                return self._parse_windows_output(result.stdout)
            else:
                # Unix-based systems
                scan_path = '/home' if quick else '/'
                cmd = self.av_config['scan_cmd'] + [scan_path]
                result = subprocess.run(cmd, capture_output=True, text=True)
                return self._parse_unix_output(result.stdout)
        except Exception as e:
            logger.error(f"Antivirus scan failed: {str(e)}")
            return []

    def _custom_high_risk_scan(self):
        """Scan high-risk locations with custom detection logic"""
        suspicious_files = []
        
        # Define high-risk locations based on OS
        if self.system_type == 'windows':
            high_risk_paths = [
                os.path.join(os.environ.get('TEMP', ''), ''),
                os.path.join(os.environ.get('APPDATA', ''), ''),
                os.path.join(os.environ.get('LOCALAPPDATA', ''), '')
            ]
        else:
            high_risk_paths = [
                '/tmp',
                '/var/tmp',
                f'/home/{getuser()}/.ssh'
            ]
            
        # Suspicious file patterns
        suspicious_patterns = [
            r'.*\.exe$', r'.*\.dll$', r'.*\.sh$', r'.*\.jar$',
            r'.*\.ps1$', r'.*\.vbs$', r'.*\.bat$', r'.*\.js$'
        ]
            
        # Scan high-risk paths
        for path in high_risk_paths:
            if not os.path.exists(path):
                continue
                
            for root, _, files in os.walk(path):
                for file in files:
                    if any(re.match(pattern, file) for pattern in suspicious_patterns):
                        full_path = os.path.join(root, file)
                        
                        # Calculate file hash and check against threat intel
                        try:
                            with open(full_path, 'rb') as f:
                                file_hash = hashlib.md5(f.read()).hexdigest()
                                
                            if self.threat_intel.is_hash_malicious(file_hash):
                                suspicious_files.append({
                                    'path': full_path,
                                    'reason': 'Hash match in threat intelligence',
                                    'hash': file_hash,
                                    'risk': 'Critical'
                                })
                        except Exception:
                            pass
                            
        return suspicious_files

    def _memory_scan(self):
        """Scan process memory for indicators of fileless malware"""
        memory_threats = []
        
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                # Skip system processes that would cause permission errors
                if (self.system_type != 'windows' and proc.pid < 100) or \
                   (self.system_type == 'windows' and proc.name() in ['System', 'Registry']):
                    continue
                    
                # Check command line for suspicious patterns
                cmdline = ' '.join(proc.cmdline() or [])
                if cmdline and self.threat_intel.detect_attack_pattern(cmdline):
                    memory_threats.append({
                        'process': proc.name(),
                        'pid': proc.pid,
                        'cmdline': cmdline,
                        'reason': 'Suspicious command line arguments',
                        'risk': 'High'
                    })
            except (psutil.AccessDenied, psutil.NoSuchProcess):
                continue
                
        return memory_threats

    def _parse_windows_output(self, output):
        threats = []
        for line in output.splitlines():
            if "ThreatID" in line or "DetectionID" in line:
                parts = line.split(":", 1)
                if len(parts) > 1:
                    threats.append({
                        'threat': parts[1].strip(),
                        'type': 'Windows Defender Detection',
                        'risk': 'High'
                    })
        return threats

    def _parse_unix_output(self, output):
        threats = []
        for line in output.splitlines():
            if " FOUND" in line:
                parts = line.split(":", 1)
                if len(parts) > 1:
                    threat_path = parts[0].strip()
                    threat_name = parts[1].replace(" FOUND", "").strip()
                    threats.append({
                        'path': threat_path,
                        'threat': threat_name,
                        'type': 'ClamAV Detection',
                        'risk': 'High'
                    })
        return threats

    def quarantine_file(self, file_path):
        """Safely quarantine a suspicious file"""
        try:
            quarantine_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'quarantine')
            os.makedirs(quarantine_dir, exist_ok=True)
            
            # Create encrypted copy in quarantine
            with open(file_path, 'rb') as f:
                file_data = f.read()
                
            encrypted_data = cipher_suite.encrypt(file_data)
            quarantine_name = os.path.join(
                quarantine_dir, 
                f"{hashlib.md5(file_path.encode()).hexdigest()}_{os.path.basename(file_path)}.quarantine"
            )
            
            with open(quarantine_name, 'wb') as f:
                f.write(encrypted_data)
                
            # Rename original file to prevent execution
            os.rename(file_path, f"{file_path}.aegis_locked")
            
            logger.info(f"File quarantined: {file_path} -> {quarantine_name}")
            return True
        except Exception as e:
            logger.error(f"Failed to quarantine file {file_path}: {str(e)}")
            return False

# ========================
# ADAPTIVE PROCESS GUARDIAN
# ========================
class AdaptiveProcessGuardian:
    def __init__(self, threat_intel):
        self.threat_intel = threat_intel
        self.baseline = {}
        self.learned_patterns = {}
        self.suspicious_patterns = [
            r"\.js$", r"\.vbs$", r"tmp[\w-]+\.exe$", r"svchost", r"lsass", 
            r"powershell", r"cmd.exe", r"bash", r"python", r"perl"
        ]
        self.critical_processes = self._get_critical_processes()
        self.whitelist = ["system", "ntoskrnl.exe", getuser().lower(), "svchost.exe", "explorer.exe"]
        self.high_risk_procs = []
        self.last_scan = datetime.now()
        
    def _get_critical_processes(self):
        if platform.system().lower() == 'windows':
            return ["lsass.exe", "services.exe", "winlogon.exe", "csrss.exe"]
        else:
            return ["systemd", "init", "cron", "sshd"]
    
    def establish_baseline(self):
        """Create a baseline of normal system process behavior"""
        console.print("[cyan]Establishing process baseline...[/]")
        
        for proc in psutil.process_iter(['pid', 'name', 'exe', 'cmdline', 'cpu_percent', 'memory_percent']):
            try:
                proc_info = proc.info
                if proc_info['name'] not in self.baseline:
                    self.baseline[proc_info['name']] = {
                        'count': 0,
                        'avg_cpu': 0,
                        'avg_memory': 0,
                        'known_paths': set(),
                        'known_cmdlines': set(),
                        'first_seen': datetime.now()
                    }
                    
                self.baseline[proc_info['name']]['count'] += 1
                self.baseline[proc_info['name']]['avg_cpu'] += (proc_info['cpu_percent'] or 0)
                self.baseline[proc_info['name']]['avg_memory'] += (proc_info['memory_percent'] or 0)
                
                if proc_info['exe']:
                    self.baseline[proc_info['name']]['known_paths'].add(proc_info['exe'])
                    
                if proc_info['cmdline']:
                    cmdline = ' '.join(proc_info['cmdline'])
                    if len(cmdline) < 200:  # Avoid storing huge command lines
                        self.baseline[proc_info['name']]['known_cmdlines'].add(cmdline)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
                
        # Calculate averages
        for proc_name in self.baseline:
            if self.baseline[proc_name]['count'] > 0:
                self.baseline[proc_name]['avg_cpu'] /= self.baseline[proc_name]['count']
                self.baseline[proc_name]['avg_memory'] /= self.baseline[proc_name]['count']
                
        logger.info(f"Established baseline for {len(self.baseline)} processes")
        return self.baseline
    
    def analyze_process(self, proc):
        """Analyze a process for suspicious behavior"""
        try:
            proc_info = proc.as_dict(attrs=[
                'pid', 'name', 'exe', 'cmdline', 'cpu_percent', 
                'memory_percent', 'create_time', 'connections', 
                'username', 'open_files'
            ])
            
            # Initialize risk assessment
            risk_assessment = {
                'risk_score': 0,
                'risk_factors': [],
                'pid': proc_info['pid'],
                'name': proc_info['name'],
                'path': proc_info['exe'],
                'user': proc_info['username'],
                'cmdline': ' '.join(proc_info['cmdline'] or []),
                'creation_time': datetime.fromtimestamp(proc_info['create_time']).strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # === RISK FACTOR: Name patterns ===
            if any(re.search(p, proc_info['name'], re.I) for p in self.suspicious_patterns):
                risk_assessment['risk_score'] += 20
                risk_assessment['risk_factors'].append("Suspicious process name pattern")
                
            # === RISK FACTOR: Critical process impersonation ===
            if proc_info['name'] in self.critical_processes and proc_info['exe'] and \
               not any(legitimate_path in proc_info['exe'].lower() for legitimate_path in [
                   'windows', 'system32', '/usr/sbin', '/usr/bin', '/bin', '/sbin'
               ]):
                risk_assessment['risk_score'] += 50
                risk_assessment['risk_factors'].append("Critical process impersonation")
                
            # === RISK FACTOR: Resource usage ===
            if proc_info.get('cpu_percent', 0) > 80:
                risk_assessment['risk_score'] += 15
                risk_assessment['risk_factors'].append("High CPU usage")
                
            if proc_info.get('memory_percent', 0) > 70:
                risk_assessment['risk_score'] += 15
                risk_assessment['risk_factors'].append("High memory usage")
                
            # === RISK FACTOR: Baseline deviation ===
            if proc_info['name'] in self.baseline:
                baseline_data = self.baseline[proc_info['name']]
                
                # Check CPU deviation
                if proc_info['cpu_percent'] and proc_info['cpu_percent'] > baseline_data['avg_cpu'] * 3:
                    risk_assessment['risk_score'] += 15
                    risk_assessment['risk_factors'].append("Abnormal CPU usage")
                    
                # Check memory deviation
                if proc_info['memory_percent'] and proc_info['memory_percent'] > baseline_data['avg_memory'] * 3:
                    risk_assessment['risk_score'] += 15
                    risk_assessment['risk_factors'].append("Abnormal memory usage")
                    
                # Check unexpected path
                if proc_info['exe'] and proc_info['exe'] not in baseline_data['known_paths']:
                    risk_assessment['risk_score'] += 25
                    risk_assessment['risk_factors'].append("Unusual executable path")
                    
                # Check command line
                cmdline = ' '.join(proc_info['cmdline'] or [])
                if cmdline and cmdline not in baseline_data['known_cmdlines']:
                    # Check for suspicious command line patterns
                    if any(self.threat_intel.detect_attack_pattern(cmdline)):
                        risk_assessment['risk_score'] += 35
                        risk_assessment['risk_factors'].append("Malicious command line pattern")
                    else:
                        risk_assessment['risk_score'] += 10
                        risk_assessment['risk_factors'].append("Unusual command line arguments")
            else:
                # Process not in baseline
                risk_assessment['risk_score'] += 10
                risk_assessment['risk_factors'].append("New process not in baseline")
                
            # === RISK FACTOR: Recent creation ===
            age = time.time() - proc_info.get('create_time', time.time())
            if age < 300:  # 5 minutes
                risk_assessment['risk_score'] += 15
                risk_assessment['risk_factors'].append("Recently created process")
                
            # === RISK FACTOR: Network connections ===
            if proc_info.get('connections') and len(proc_info['connections']) > 0:
                # Check for outbound connections
                outbound = [conn for conn in proc_info['connections'] 
                           if conn.status == 'ESTABLISHED' and conn.raddr]
                
                if outbound:
                    risk_assessment['risk_score'] += 10
                    risk_assessment['risk_factors'].append(f"Active network connections ({len(outbound)})")
                    
                    # Check for connections to malicious IPs
                    malicious_connections = [conn for conn in outbound 
                                           if conn.raddr and self.threat_intel.is_ip_malicious(conn.raddr.ip)]
                    
                    if malicious_connections:
                        risk_assessment['risk_score'] += 50
                        risk_assessment['risk_factors'].append("Connection to known malicious IP")
            
            # === RISK FACTOR: Privileged user ===
            if proc_info['username'] and proc_info['username'].lower() in ['system', 'root', 'administrator']:
                risk_assessment['risk_score'] += 10
                risk_assessment['risk_factors'].append("Running as privileged user")
                
            # Apply whitelist reduction
            if proc_info['name'].lower() in self.whitelist:
                risk_assessment['risk_score'] = max(0, risk_assessment['risk_score'] - 40)
                
            # Ensure critical system processes don't get flagged unless truly suspicious
            if proc_info['name'] in self.critical_processes and risk_assessment['risk_score'] < 50:
                risk_assessment['risk_score'] = 0
                risk_assessment['risk_factors'] = []
                
            return risk_assessment
            
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return {}

    def monitor_processes(self, threshold=50):
        """Continuously monitor processes for suspicious activity"""
        # First establish baseline if it doesn't exist
        if not self.baseline:
            self.establish_baseline()
            
        # Clear previous high risk processes
        self.high_risk_procs.clear()
        
        try:
            with ThreadPoolExecutor(max_workers=min(os.cpu_count() or 4, 8)) as executor:
                # Submit all processes for analysis
                futures = {executor.submit(self.analyze_process, proc): proc for proc in psutil.process_iter()}
                
                # Process results as they complete
                for future in futures:
                    try:
                        result = future.result()
                        if result and result.get('risk_score', 0) >= threshold:
                            self.high_risk_procs.append(result)
                    except Exception:
                        continue
        except Exception as e:
            logger.error(f"Error during process monitoring: {str(e)}")
            
        # Log high risk processes
        for proc in self.high_risk_procs:
            risk_factors = ", ".join(proc['risk_factors'])
            logger.warning(
                f"High risk process detected: {proc['name']} (PID: {proc['pid']}) - "
                f"Score: {proc['risk_score']} - Factors: {risk_factors}"
            )
            
        # Update last scan time
        self.last_scan = datetime.now()
        return self.high_risk_procs
        
    def terminate_process(self, pid, force=False):
        """Terminate a suspicious process"""
        try:
            proc = psutil.Process(pid)
            
            # Extra safety check for critical processes
            if proc.name() in self.critical_processes and not force:
                logger.warning(f"Refusing to terminate critical process {proc.name()} (PID: {pid}) without force flag")
                return False
                
            # Normal termination
            proc.terminate()
            
            # Wait briefly and check if process is still running
            time.sleep(1)
            if psutil.pid_exists(pid):
                if force:
                    # Force kill if process is stubborn
                    proc.kill()
                    logger.info(f"Force killed process {proc.name()} (PID: {pid})")
                else:
                    logger.warning(f"Process {proc.name()} (PID: {pid}) resisted termination")
                    return False
                    
            logger.info(f"Successfully terminated process {proc.name()} (PID: {pid})")
            return True
        except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
            logger.error(f"Failed to terminate process (PID: {pid}): {str(e)}")
            return False

# ========================
# PROMETHEUS NETWORK SENTRY
# ========================
class PrometheusNetworkSentry:
    def __init__(self, threat_intel):
        self.threat_intel = threat_intel
        self.dangerous_ports = {
            22: 'SSH', 23: 'Telnet', 445: 'SMB', 3389: 'RDP', 
            4444: 'Metasploit', 5900: 'VNC', 6667: 'IRC',
            1433: 'MSSQL', 3306: 'MySQL', 5432: 'PostgreSQL'
        }
        self.port_history = {}
        self.connection_history = {}
        self.last_scan = datetime.now()
        
    def inspect_connections(self, threshold=50):
        """Inspect all network connections and evaluate risk"""
        alerts = []
        connections = psutil.net_connections()
        current_time = datetime.now()
        
        # Update connection history
        for conn in connections:
            # Skip connections without an associated process
            if not conn.pid:
                continue
                
            # Create connection key based on local and remote addresses
            conn_key = f"{conn.laddr.ip}:{conn.laddr.port}"
            if conn.raddr:
                conn_key += f"->{conn.raddr.ip}:{conn.raddr.port}"
                
            if conn_key not in self.connection_history:
                self.connection_history[conn_key] = {
                    'first_seen': current_time,
                    'last_seen': current_time,
                    'pid': conn.pid,
                    'status': conn.status,
                    'count': 1
                }
            else:
                self.connection_history[conn_key]['last_seen'] = current_
                self.connection_history[conn_key]['last_seen'] = current_time
                self.connection_history[conn_key]['count'] += 1
                
        # Process current connections for alerts
        for conn in connections:
            if not conn.pid:
                continue
                
            risk_assessment = {
                'risk_score': 0,
                'risk_factors': [],
                'pid': conn.pid,
                'port': conn.laddr.port if conn.laddr else None,
                'local_address': f"{conn.laddr.ip}:{conn.laddr.port}" if conn.laddr else "Unknown",
                'remote_address': f"{conn.raddr.ip}:{conn.raddr.port}" if conn.raddr else "N/A",
                'status': conn.status
            }
            
            # Check for listening on dangerous ports
            if conn.status == 'LISTEN' and conn.laddr:
                port = conn.laddr.port
                
                # Track port history
                if port not in self.port_history:
                    self.port_history[port] = {
                        'first_seen': current_time,
                        'last_seen': current_time,
                        'pid_history': {conn.pid: 1},
                        'count': 1
                    }
                else:
                    self.port_history[port]['last_seen'] = current_time
                    self.port_history[port]['count'] += 1
                    if conn.pid in self.port_history[port]['pid_history']:
                        self.port_history[port]['pid_history'][conn.pid] += 1
                    else:
                        self.port_history[port]['pid_history'][conn.pid] = 1
                
                # Known dangerous port
                if port in self.dangerous_ports:
